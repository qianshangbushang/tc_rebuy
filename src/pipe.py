import lightgbm as lgb
import numpy as np
import pandas as pd
import xgboost as xgb
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from pydantic import BaseModel
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

from feature.behavior_transformer import BehaviorTransformer
from feature.matrix_transformer import MatrixTransformer
from feature.prev_transformer import PrevTransformer
from feature.tfidf_transformer import TfidfTransformer

try:
    from .data import load_data, load_dataframe
except ImportError:
    from data import load_data, load_dataframe


class ModelConfig(BaseModel):
    model_type: str = "rf"  # å¯é€‰ 'rf', 'xgb', 'lgb'
    n_estimators: int = 200
    max_depth: int = 10
    learning_rate: float = 0.1
    scale_pos_weight: float = 7.0  # ç”¨äºå¤„ç†ç±»åˆ«ä¸å¹³è¡¡


class TCDataConfig(BaseModel):
    fill_median_cols: list[str] = []
    fill_mode_cols: list[str] = []

    cache_behavior_feature: bool = True
    cache_behavior_path: str = "../data/behavior_feature.pkl"

    cache_tfidf_feature: bool = True
    cache_tfidf_path: str = "../data/tfidf_feature.pkl"

    cache_matrix_feature: bool = True
    cache_matrix_path: str = "../data/matrix_feature.pkl"

    cache_prev_feature: bool = True
    cache_prev_path: str = "../data/prev_feature.pkl"
    model: ModelConfig = ModelConfig()


def create_clean_pipeline(conf: TCDataConfig) -> Pipeline:
    """Create a data cleaning pipeline."""
    column_transformer = ColumnTransformer(
        [
            ("median_fill", SimpleImputer(strategy="median"), conf.fill_median_cols),
            ("mode_fill", SimpleImputer(strategy="most_frequent"), conf.fill_mode_cols),
        ],
        remainder="passthrough",
        verbose_feature_names_out=False,
        verbose=True,
    )
    column_transformer.set_output(transform="pandas")

    steps = [
        ("column_transformer", column_transformer),
    ]
    return Pipeline(steps, verbose=True)


def create_sample_pipeline(conf: TCDataConfig):
    """åˆ›å»ºæ•°æ®é‡‡æ ·ç®¡é“"""
    try:
        steps = [("smote", SMOTE(random_state=42, k_neighbors=5))]

        return ImbPipeline(steps)
    except ImportError:
        print("âš ï¸ imbalanced-learn æœªå®‰è£…ï¼Œè·³è¿‡é‡‡æ ·ç®¡é“")
        return None


def create_model_pipeline(conf: ModelConfig) -> Pipeline:
    """åˆ›å»ºæ¨¡å‹è®­ç»ƒç®¡é“ï¼Œæ”¯æŒå¤šç§æ¨¡å‹"""
    steps = [("scaler", StandardScaler())]

    if conf.model_type == "rf":
        classifier = RandomForestClassifier(
            n_estimators=conf.n_estimators,
            max_depth=conf.max_depth,
            random_state=42,
            n_jobs=-1,
            class_weight="balanced",
        )
    elif conf.model_type == "xgb":
        if xgb is None:
            raise ImportError("XGBoost æœªå®‰è£…ï¼Œè¯·å®‰è£…åä½¿ç”¨: pip install xgboost")
        classifier = xgb.XGBClassifier(
            n_estimators=conf.n_estimators,
            max_depth=conf.max_depth,
            random_state=42,
            n_jobs=-1,
            scale_pos_weight=conf.scale_pos_weight,
        )
    elif conf.model_type == "lgb":
        if lgb is None:
            raise ImportError("LightGBM æœªå®‰è£…ï¼Œè¯·å®‰è£…åä½¿ç”¨: pip install lightgbm")
        classifier = lgb.LGBMClassifier(
            n_estimators=conf.n_estimators,
            max_depth=conf.max_depth,
            random_state=42,
            n_jobs=-1,
            class_weight="balanced",
        )
    else:
        raise ValueError("model_type å¿…é¡»æ˜¯ 'rf', 'xgb' æˆ– 'lgb'")

    steps.append(("classifier", classifier))
    return Pipeline(steps)


class TCDataPipeline:
    def __init__(self, conf: TCDataConfig):
        self.conf = conf

        self.behavior_transformer = BehaviorTransformer(
            enable_cache=conf.cache_behavior_feature,
            cache_path=conf.cache_behavior_path,
        )

        self.tfidf_transformer = TfidfTransformer(
            enable_cache=conf.cache_tfidf_feature,
            cache_path=conf.cache_tfidf_path,
        )

        self.matrix_transformer = MatrixTransformer(
            n_components=80, random_state=42, enable_cache=conf.cache_matrix_feature, cache_path=conf.cache_matrix_path
        )
        self.prev_transformer = PrevTransformer(enable_cache=conf.cache_prev_feature, cache_path=conf.cache_prev_path)
        self.clean_pipe = create_clean_pipeline(conf)
        self.sample_pipe = None  # create_sample_pipeline(conf)
        self.model_pipe = create_model_pipeline(conf.model)

        # å­˜å‚¨æ•°æ®é›†
        self.X_train = None
        self.X_val = None
        self.X_test = None
        self.y_train = None
        self.y_val = None
        self.y_test = None

        # å­˜å‚¨æ¸…æ´—åçš„å®Œæ•´æ•°æ®
        self.X_clean = None
        self.y_clean = None

        # è®­ç»ƒçŠ¶æ€
        self.is_fitted = False

    def preprocess(self, X: pd.DataFrame, y: pd.Series = None):
        """
        ä»…è¿›è¡Œæ•°æ®æ¸…æ´—å’Œç‰¹å¾å·¥ç¨‹
        """
        self.behavior_transformer.fit(X, y)
        self.tfidf_transformer.fit(X, y)
        self.matrix_transformer.fit(X, y)
        self.prev_transformer.fit(X, y)

        train_mask = y.isin([0, 1])
        test_mask = y.isnull()

        X_train, y_train = X[train_mask], y[train_mask]
        X_test, y_test = X[test_mask], y[test_mask]

        X_train = self.behavior_transformer.transform(X_train)
        X_test = self.behavior_transformer.transform(X_test)

        X_train = self.tfidf_transformer.transform(X_train)
        X_test = self.tfidf_transformer.transform(X_test)

        X_train = self.matrix_transformer.transform(X_train)
        X_test = self.matrix_transformer.transform(X_test)

        X_train = self.prev_transformer.transform(X_train)
        X_test = self.prev_transformer.transform(X_test)

        print("ç‰¹å¾å¤„ç†å®Œæˆ, å½“å‰æ•°æ®å½¢çŠ¶:")
        print(f"è®­ç»ƒé›†: {X_train.shape},  æµ‹è¯•é›†: {X_test.shape}")
        drop_cols = ["user_id", "merchant_id", "activity_log"]
        X_train = X_train.drop(columns=[col for col in drop_cols if col in X_train.columns], errors="ignore")
        # X_test = X_test.drop(columns=[col for col in drop_cols if col in X_test.columns], errors="ignore")

        return X_train, y_train, X_test, y_test

    def fit(self, X, y):
        """
        å®Œæ•´çš„è®­ç»ƒæµç¨‹
        """
        train_X, train_y, test_X, test_y = self.preprocess(X, y)
        self.summary(train_X, None, test_X)

        if self.sample_pipe is not None and train_X is not None:
            print("\nğŸ”„ Step 3: æ•°æ®é‡‡æ ·...")
            try:
                train_X, train_y = self.sample_pipe.fit_resample(train_X, train_y)
                print(f"âœ… é‡‡æ ·åè®­ç»ƒé›†å½¢çŠ¶: {train_X.shape}")
                print(f"âœ… é‡‡æ ·åæ ‡ç­¾åˆ†å¸ƒ:\n{pd.Series(train_y).value_counts()}")
            except Exception as e:
                print(f"âš ï¸ é‡‡æ ·å¤±è´¥ï¼Œè·³è¿‡é‡‡æ ·æ­¥éª¤: {e}")

        # 4. æ¨¡å‹è®­ç»ƒ (å¦‚æœæœ‰è®­ç»ƒæ•°æ®ä¸”é…ç½®äº†æ¨¡å‹ç®¡é“)
        if self.model_pipe is not None and train_X is not None and train_y is not None:
            print("\nğŸ”„ Step 4: æ¨¡å‹è®­ç»ƒ...")
            try:
                self.feature_names = train_X.columns.tolist()
                self.model_pipe.fit(train_X, train_y)
                print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
                self.is_fitted = True
            except Exception as e:
                print(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
                self.is_fitted = False
        return self

    def transform(self, X):
        """å¯¹æ–°æ•°æ®è¿›è¡Œé¢„å¤„ç†"""
        if self.clean_pipe is None:
            raise ValueError("Pipeline has not been fitted yet.")

        return self.clean_pipe.transform(X)

    def predict(self, X):
        """é¢„æµ‹æ–°æ•°æ®"""
        if not self.is_fitted:
            raise ValueError("Model has not been trained yet.")

        # X_processed = self.transform(X)
        return self.model_pipe.predict(X[self.feature_names])

    def predict_proba(self, X):
        """é¢„æµ‹æ¦‚ç‡"""
        if not self.is_fitted:
            raise ValueError("Model has not been trained yet.")

        # X_processed = self.transform(X)
        return self.model_pipe.predict_proba(X[self.feature_names])

    def evaluate(self, val_X, val_y):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        if not self.is_fitted:
            raise ValueError("Model has not been trained yet.")

        if val_X is None or val_y is None:
            print("âŒ éªŒè¯é›†æ•°æ®ä¸å­˜åœ¨")
            return None

        # è¿‡æ»¤æ‰ç©ºæ ‡ç­¾
        mask = val_y.notna()
        if not mask.any():
            print("âŒ éªŒè¯é›†æ²¡æœ‰æœ‰æ•ˆæ ‡ç­¾")
            return None

        X_eval_clean = val_X[mask]
        y_eval_clean = val_y[mask]

        # é¢„æµ‹
        y_pred = self.model_pipe.predict(X_eval_clean[self.feature_names])

        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(y_eval_clean, y_pred)

        print("ğŸ“Š éªŒè¯é›†è¯„ä¼°ç»“æœ:")
        print(f"å‡†ç¡®ç‡: {accuracy:.4f}")

        # å¦‚æœæ˜¯äºŒåˆ†ç±»ï¼Œè®¡ç®—AUC
        if hasattr(self.model_pipe, "predict_proba") and len(np.unique(y_eval_clean)) == 2:
            try:
                y_pred_proba = self.model_pipe.predict_proba(X_eval_clean[self.feature_names])
                auc = roc_auc_score(y_eval_clean, y_pred_proba[:, 1])
                print(f"AUC: {auc:.4f}")
            except Exception as e:
                print(f"âš ï¸ AUCè®¡ç®—å¤±è´¥: {e}")
                auc = None
        else:
            auc = None

        print(f"\nè¯¦ç»†æŠ¥å‘Š:\n{classification_report(y_eval_clean, y_pred)}")

        return {
            "accuracy": accuracy,
            "auc": auc,
            "y_true": y_eval_clean,
            "y_pred": y_pred,
        }

    def get_feature_importance(self, top_n=20):
        """è·å–ç‰¹å¾é‡è¦æ€§"""
        if not self.is_fitted:
            print("æ¨¡å‹å°šæœªè®­ç»ƒ")
            return None

        # å°è¯•è·å–ç‰¹å¾é‡è¦æ€§
        model = self.model_pipe
        if hasattr(model, "named_steps"):
            # å¦‚æœæ˜¯Pipelineï¼Œè·å–æœ€åä¸€ä¸ªæ­¥éª¤
            final_step = list(model.named_steps.values())[-1]
        else:
            final_step = model

        if hasattr(final_step, "feature_importances_"):
            importances = final_step.feature_importances_
            feature_names = self.X_train.columns

            # åˆ›å»ºç‰¹å¾é‡è¦æ€§DataFrame
            importance_df = pd.DataFrame({"feature": feature_names, "importance": importances}).sort_values(
                "importance", ascending=False
            )

            print(f"ğŸ” Top {top_n} é‡è¦ç‰¹å¾:")
            print(importance_df.head(top_n))

            return importance_df
        else:
            print("æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§åˆ†æ")
            return None

    def summary(self, train_X, val_X, test_X):
        """æ‰“å°ç®¡é“æ‘˜è¦ä¿¡æ¯"""
        print("ğŸ“‹ TCDataPipeline æ‘˜è¦:")
        print(f"æ•°æ®æ¸…æ´—ç®¡é“: {self.clean_pipe is not None}")
        print(f"é‡‡æ ·ç®¡é“: {self.sample_pipe is not None}")
        print(f"æ¨¡å‹ç®¡é“: {self.model_pipe is not None}")
        print(f"æ¨¡å‹å·²è®­ç»ƒ: {self.is_fitted}")

        if train_X is not None:
            print(f"è®­ç»ƒé›†: {train_X.shape}")
        if val_X is not None:
            print(f"éªŒè¯é›†: {val_X.shape}")
        if test_X is not None:
            print(f"æµ‹è¯•é›†: {test_X.shape}")

    def tune_model(self, X, y, param_grid=None, search_type="grid", cv=3, scoring="roc_auc", n_iter=20):
        """
        è‡ªåŠ¨è°ƒå‚ï¼Œæ”¯æŒ RF/XGB/LGB
        param_grid: dictï¼Œå‚æ•°æœç´¢ç©ºé—´
        search_type: "grid" æˆ– "random"
        """

        train_X, train_y, _, _ = self.preprocess(X, y)
        if train_X is None or train_y is None:
            print("âŒ è®­ç»ƒé›†ä¸å­˜åœ¨ï¼Œæ— æ³•è°ƒå‚")
            return None

        if param_grid is None:
            # é»˜è®¤å‚æ•°ç©ºé—´
            if self.conf.model.model_type == "rf":
                param_grid = {
                    "classifier__n_estimators": [100, 200, 500],
                    "classifier__max_depth": [4, 6, 10, 16],
                }
            elif self.conf.model.model_type == "xgb":
                param_grid = {
                    "classifier__n_estimators": [200, 500, 1000],
                    "classifier__max_depth": [4, 6, 10],
                    "classifier__learning_rate": [0.05, 0.1, 0.2],
                    "classifier__scale_pos_weight": [5, 7, 10],
                }
            elif self.conf.model.model_type == "lgb":
                param_grid = {
                    "classifier__n_estimators": [
                        # 900,
                        # 1000,
                        1100,
                        # 1200,
                    ],
                    "classifier__max_depth": [3],
                    "classifier__learning_rate": [0.05],
                    "classifier__class_weight": [None],
                }

        search_cls = GridSearchCV if search_type == "grid" else RandomizedSearchCV

        if search_type == "grid":
            search = search_cls(
                self.model_pipe,
                param_grid,
                cv=cv,
                scoring=scoring,
                verbose=2,
                n_jobs=12,
            )
        else:
            search = search_cls(
                self.model_pipe,
                param_grid,
                cv=cv,
                scoring=scoring,
                n_iter=n_iter,
                verbose=2,
                n_jobs=-1,
            )
        print("ğŸ” å¼€å§‹æ¨¡å‹è°ƒå‚...")
        search.fit(train_X, train_y)
        print(f"âœ… æœ€ä¼˜å‚æ•°: {search.best_params_}")
        print(f"âœ… æœ€ä¼˜åˆ†æ•°: {search.best_score_:.4f}")

        self.model_pipe = search.best_estimator_
        self.is_fitted = True
        return search

    def export_prediction(self, X: pd.DataFrame, y, filename="prediction.csv"):
        """
        å¯¼å‡ºé¢„æµ‹ç»“æœåˆ° prediction.csv
        æ ¼å¼ï¼šuser_id, merchant_id, prob
        """
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œæ— æ³•å¯¼å‡ºé¢„æµ‹ç»“æœã€‚")

        _, _, X_test, _ = self.preprocess(X, y)

        # åªä¿ç•™è®­ç»ƒç”¨çš„ç‰¹å¾
        drop_cols = ["user_id", "merchant_id", "activity_log"]
        X_pred = X_test.drop(columns=[col for col in drop_cols if col in X_test.columns], errors="ignore")

        # é¢„æµ‹æ¦‚ç‡
        prob = self.predict_proba(X_pred)[:, 1]  # å–æ­£ç±»æ¦‚ç‡

        # æ„å»ºç»“æœ DataFrame
        result = pd.DataFrame(
            {"user_id": X_test["user_id"].values, "merchant_id": X_test["merchant_id"].values, "prob": prob}
        )

        # ä¿å­˜ä¸º CSV
        result.to_csv(filename, index=False)
        print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ° {filename}")


def analysis():
    """Perform data analysis."""
    dataset = load_data()

    print("train f1 info:")
    print(dataset.train_f1.info())
    print("=" * 50)

    print("user f1 info: ")
    print(dataset.user_f1.info())
    print("=" * 50)

    print("log f1 info: ")
    print(dataset.log_f1.info())
    print("=" * 50)

    print("train f2 info: ")
    print(dataset.train_f2.info())
    print("=" * 50)

    print("test f2 info:")
    print(dataset.test_f2.info())
    print("=" * 50)


def run():
    df = load_dataframe(nrow=None)
    X, y = df.drop(columns=["label"]), df["label"]
    pipe = create_clean_pipeline(
        TCDataConfig(
            fill_median_cols=["age_range"],
            fill_mode_cols=["gender"],
        )
    )
    pipe = TCDataPipeline(
        TCDataConfig(
            fill_median_cols=["age_range"],
            fill_mode_cols=["gender"],
            # cache_behavior_feature=True,
            # cache_behavior_path="../data/cleaned_data.pkl",
            model=ModelConfig(model_type="lgb", n_estimators=500, max_depth=4, scale_pos_weight=7.0),
        )
    )

    pipe.fit(X, y)
    # pipe.tune_model(X, y)

    if pipe.is_fitted:
        pipe.export_prediction(X, y, filename="../output/prediction.csv")


if __name__ == "__main__":
    run()
