import os
import pickle

import numpy as np
import pandas as pd
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from pydantic import BaseModel
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

try:
    from .data import load_data, load_dataframe
except ImportError:
    from data import load_data, load_dataframe


class TCDataConfig(BaseModel):
    fill_median_cols: list[str] = []
    fill_mode_cols: list[str] = []

    cache_clean_result: bool = False
    cache_clean_path: str = "data/cleaned_data.pkl"


class UserMerchantFeatureTransformer(BaseEstimator, TransformerMixin):
    def __init__(self):
        self.user_merchant_features = None
        return

    def fit(self, X, y=None):
        X_copy = X.copy()

        user_merchant_interactions = X_copy.groupby(["user_id", "merchant_id"]).size()
        user_total_interactions = X_copy.groupby("user_id").size()

        user_merchant_ratio = (
            user_merchant_interactions.div(user_total_interactions, level="user_id")
            .reset_index()
            .rename(columns={0: "user_merchant_interaction_ratio"})
        )

        merchant_total_interactions = X_copy.groupby("merchant_id").size()
        merchant_user_ratio = (
            user_merchant_interactions.div(merchant_total_interactions, level="merchant_id")
            .reset_index()
            .rename(columns={0: "merchant_user_interaction_ratio"})
        )

        user_merchant_features = user_merchant_ratio.merge(
            merchant_user_ratio, on=["user_id", "merchant_id"], how="outer"
        )

        self.user_merchant_features = user_merchant_features
        return self

    def transform(self, X):
        """âœ… å®ç°ç‰¹å¾åˆå¹¶é€»è¾‘"""
        if self.user_merchant_features is None:
            raise ValueError("Transformer has not been fitted yet.")

        X_transformed = X.copy()

        # åˆå¹¶ç”¨æˆ·-å•†æˆ·äº¤äº’ç‰¹å¾
        if all(col in X_transformed.columns for col in ["user_id", "merchant_id"]):
            X_transformed = X_transformed.merge(self.user_merchant_features, on=["user_id", "merchant_id"], how="left")
        else:
            print("âš ï¸ è¾“å…¥æ•°æ®ç¼ºå°‘ user_id æˆ– merchant_id åˆ—ï¼Œè·³è¿‡ç”¨æˆ·-å•†æˆ·ç‰¹å¾åˆå¹¶")

        return X_transformed


class UserFeatureTransformer(BaseEstimator, TransformerMixin):
    def __init__(self):
        self.features = None
        return

    def fit(self, X, y=None):
        X_copy = X.copy()
        X_copy = X_copy[X_copy["activity_log"].notnull()]
        X_copy = X_copy.assign(activity_log=X_copy["activity_log"].str.split("#")).explode("activity_log")

        X_copy[["item_id", "cate_id", "brand_id", "time", "action_type"]] = X_copy["activity_log"].str.split(
            ":", expand=True
        )

        # æ¯ä¸ªç”¨æˆ·ä¸åŒactionç±»å‹çš„è¡Œä¸ºå æ¯”
        action_ratio = (
            X_copy.groupby(["user_id", "action_type"])
            .size()
            .div(X_copy.groupby("user_id").size(), level="user_id")
            .unstack(fill_value=0)
            .add_prefix("action_ratio_")
        )
        action_ratio.columns.name = None

        # è®¡ç®—æ¯ä¸ªç”¨æˆ·æ¯ä¸ªæœˆçš„è¡Œä¸ºå æ¯”
        X_copy["month"] = X_copy["time"].str[:2].astype(int)
        time_ratio = (
            X_copy.groupby(["user_id", "month"])
            .size()
            .div(X_copy.groupby("user_id").size(), level="user_id")
            .unstack(fill_value=0)
            .add_prefix("time_ratio_")
        )
        time_ratio.columns.name = None

        # è®¡ç®—æ¯ä¸ªç”¨æˆ·æ¯ä¸ªæœˆä¸åŒactionçš„å æ¯”ã€‚
        time_action_ratio = X_copy.pivot_table(
            index="user_id",
            columns=["month", "action_type"],
            aggfunc="size",
            fill_value=0,
        ).div(X_copy.groupby("user_id").size(), axis=0)
        time_action_ratio.columns = [
            f"time_action_ratio_month_{month}_action_{action}" for month, action in time_action_ratio.columns
        ]

        # äº¤äº’ç»Ÿè®¡ç‰¹å¾
        user_stats = X_copy.groupby("user_id").agg(
            user_item_count=("item_id", "nunique"),
            user_cate_count=("cate_id", "nunique"),
            user_brand_count=("brand_id", "nunique"),
            user_merchant_count=("merchant_id", "nunique"),
            user_action_count=("action_type", "count"),  # æ€»è¡Œä¸ºæ¬¡æ•°
        )

        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        features = (
            action_ratio.join(time_ratio, how="outer")
            .join(time_action_ratio, how="outer")
            .join(user_stats, how="outer")
        )

        self.features = features.reset_index()
        return self

    def transform(self, X):
        # å‡è®¾ X æ˜¯ä¸€ä¸ªåŒ…å«ç”¨æˆ·ä¿¡æ¯çš„ DataFrame
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„ç‰¹å¾å·¥ç¨‹æ­¥éª¤
        if self.features is None:
            raise ValueError("The transformer has not been fitted yet.")
        X_transformed = X.copy()
        X_transformed = X_transformed.merge(self.features, how="left", on="user_id")
        return X_transformed


class MerchantFeatureTransformer(BaseEstimator, TransformerMixin):
    def __init__(self):
        self.features = None
        return

    def fit(self, X, y=None):
        X_copy = X.copy()
        X_copy = X_copy[X_copy["activity_log"].notnull()]
        X_copy = X_copy.assign(activity_log=X_copy["activity_log"].str.split("#")).explode("activity_log")

        X_copy[["item_id", "cate_id", "brand_id", "time", "action_type"]] = X_copy["activity_log"].str.split(
            ":", expand=True
        )

        # åº—é“ºå„ç§actionçš„å æ¯”
        action_ratio = (
            X_copy.groupby(["merchant_id", "action_type"])
            .size()
            .div(X_copy.groupby("merchant_id").size(), level="merchant_id")
            .unstack(fill_value=0)
            .add_prefix("merchant_action_ratio_")
        )
        action_ratio.columns.name = None

        X_copy["month"] = X_copy["time"].str[:2].astype(int)

        # è®¡ç®—æ¯ä¸ªå•†æˆ·æ¯ä¸ªæœˆçš„è¡Œä¸ºå æ¯”
        time_ratio = (
            X_copy.groupby(["merchant_id", "month"])
            .size()
            .div(X_copy.groupby("merchant_id").size(), level="merchant_id")
            .unstack(fill_value=0)
            .add_prefix("merchant_time_ratio_")
        )
        time_ratio.columns.name = None

        # è®¡ç®—æ¯ä¸ªå•†æˆ·æ¯ä¸ªæœˆä¸åŒactionçš„å æ¯”ã€‚
        time_action_ratio = X_copy.pivot_table(
            index="merchant_id",
            columns=["month", "action_type"],
            aggfunc="size",
            fill_value=0,
        ).div(X_copy.groupby(["merchant_id"]).size(), axis=0)
        time_action_ratio.columns = [
            f"merchant_time_action_ratio_month_{month}_action_{action}" for month, action in time_action_ratio.columns
        ]

        # äº¤äº’ç»Ÿè®¡ç‰¹å¾
        merch_stats = X_copy.groupby("merchant_id").agg(
            merch_item_count=("item_id", "nunique"),
            merch_cate_count=("cate_id", "nunique"),
            merch_brand_count=("brand_id", "nunique"),
            merch_user_count=("user_id", "nunique"),
            merch_action_count=("action_type", "count"),  # æ€»è¡Œä¸ºæ¬¡æ•°
        )
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        self.features = (
            action_ratio.join(time_ratio, how="outer")
            .join(time_action_ratio, how="outer")
            .join(merch_stats, how="outer")
        )

        return self

    def transform(self, X):
        X_transformed = X.copy()
        X_transformed = X_transformed.merge(self.features, how="left", on="merchant_id")
        return X_transformed


def create_clean_pipeline(conf: TCDataConfig) -> Pipeline:
    """Create a data cleaning pipeline."""
    column_transformer = ColumnTransformer(
        [
            ("median_fill", SimpleImputer(strategy="median"), conf.fill_median_cols),
            ("mode_fill", SimpleImputer(strategy="most_frequent"), conf.fill_mode_cols),
        ],
        remainder="passthrough",
        verbose_feature_names_out=False,
        verbose=True,
    )
    column_transformer.set_output(transform="pandas")

    steps = [
        ("column_transformer", column_transformer),
        ("user_feat", UserFeatureTransformer()),
        ("merch_feat", MerchantFeatureTransformer()),
        ("user_merchant_feat", UserMerchantFeatureTransformer()),
    ]
    return Pipeline(steps, verbose=True)


def create_sample_pipeline(conf: TCDataConfig):
    """åˆ›å»ºæ•°æ®é‡‡æ ·ç®¡é“"""
    try:
        steps = [("smote", SMOTE(random_state=42, k_neighbors=5))]

        return ImbPipeline(steps)
    except ImportError:
        print("âš ï¸ imbalanced-learn æœªå®‰è£…ï¼Œè·³è¿‡é‡‡æ ·ç®¡é“")
        return None


def create_model_pipeline(conf: TCDataConfig) -> Pipeline:
    """åˆ›å»ºæ¨¡å‹è®­ç»ƒç®¡é“"""
    steps = [
        ("scaler", StandardScaler()),
        (
            "classifier",
            RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1),
        ),
    ]

    return Pipeline(steps)


class TCDataPipeline:
    def __init__(self, conf: TCDataConfig):
        self.conf = conf
        self.clean_pipe = create_clean_pipeline(conf)
        self.sample_pipe = None # create_sample_pipeline(conf)
        self.model_pipe = create_model_pipeline(conf)

        # å­˜å‚¨æ•°æ®é›†
        self.X_train = None
        self.X_val = None
        self.X_test = None
        self.y_train = None
        self.y_val = None
        self.y_test = None

        # å­˜å‚¨æ¸…æ´—åçš„å®Œæ•´æ•°æ®
        self.X_clean = None
        self.y_clean = None

        # è®­ç»ƒçŠ¶æ€
        self.is_fitted = False

    def _clean(self, X, y=None):
        # 1. æ•°æ®æ¸…æ´—å’Œç‰¹å¾å·¥ç¨‹
        if self.conf.cache_clean_result:
            if os.path.exists(self.conf.cache_clean_path):
                print(f"â™»ï¸ ä»ç¼“å­˜åŠ è½½æ¸…æ´—åçš„æ•°æ®: {self.conf.cache_clean_path}")
                with open(self.conf.cache_clean_path, "rb") as f:
                    d = pickle.load(f)
                # cleaned_data = pd.read_pickle(self.conf.cache_clean_path)
                X_clean, y_clean = d["X"], d["y"]
            else:
                X_clean = self.clean_pipe.fit_transform(X, y)
                y_clean = y.copy()
                cleaned_data = {"X": X_clean, "y": y_clean}
                with open(self.conf.cache_clean_path, "wb") as f:
                    pickle.dump(cleaned_data, f)
                print(f"âœ… æ¸…æ´—åçš„æ•°æ®å·²ç¼“å­˜åˆ°: {self.conf.cache_clean_path}")
        else:
            X_clean = self.clean_pipe.fit_transform(X, y)
            y_clean = y.copy()

        self.X_clean = X_clean
        self.y_clean = y_clean

    def fit(self, X, y, val_size=0.2, random_state=42):
        """
        å®Œæ•´çš„è®­ç»ƒæµç¨‹
        """
        print("ğŸ”„ Step 1: æ•°æ®æ¸…æ´—å’Œç‰¹å¾å·¥ç¨‹...")
        self._clean(X, y)
        self.X_clean = self.X_clean.drop(columns=["user_id", "merchant_id", "activity_log"], errors="ignore")
        print(f"âœ… æ¸…æ´—åæ•°æ®å½¢çŠ¶: {self.X_clean.shape}")
        print(f"âœ… ç‰¹å¾æ•°é‡: {self.X_clean.shape[1]}")

        print("\nğŸ”„ Step 2: æ•°æ®é›†æ‹†åˆ†...")
        # 2. æ•°æ®é›†æ‹†åˆ†
        self.split_dataset(val_size, random_state)

        # 3. æ•°æ®é‡‡æ · (å¦‚æœæœ‰è®­ç»ƒæ•°æ®ä¸”é…ç½®äº†é‡‡æ ·ç®¡é“)
        if self.sample_pipe is not None and self.X_train is not None:
            print("\nğŸ”„ Step 3: æ•°æ®é‡‡æ ·...")
            try:
                self.X_train, self.y_train = self.sample_pipe.fit_resample(self.X_train, self.y_train)
                print(f"âœ… é‡‡æ ·åè®­ç»ƒé›†å½¢çŠ¶: {self.X_train.shape}")
                print(f"âœ… é‡‡æ ·åæ ‡ç­¾åˆ†å¸ƒ:\n{pd.Series(self.y_train).value_counts()}")
            except Exception as e:
                print(f"âš ï¸ é‡‡æ ·å¤±è´¥ï¼Œè·³è¿‡é‡‡æ ·æ­¥éª¤: {e}")

        # 4. æ¨¡å‹è®­ç»ƒ (å¦‚æœæœ‰è®­ç»ƒæ•°æ®ä¸”é…ç½®äº†æ¨¡å‹ç®¡é“)
        if self.model_pipe is not None and self.X_train is not None and self.y_train is not None:
            print("\nğŸ”„ Step 4: æ¨¡å‹è®­ç»ƒ...")
            try:
                self.model_pipe.fit(self.X_train, self.y_train)
                print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
                self.is_fitted = True

                # è®­ç»ƒåç«‹å³è¯„ä¼°
                if self.X_val is not None:
                    self.evaluate(stage="val")

            except Exception as e:
                print(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
                self.is_fitted = False

        return self

    def split_dataset(self, val_size=0.2, random_state=42):
        """
        æ‹†åˆ†æ•°æ®é›†ï¼Œæ”¯æŒæœ‰æµ‹è¯•é›†æ ‡ç­¾ä¸ºç©ºçš„æƒ…å†µ
        """
        X_clean = self.X_clean.reset_index(drop=True)
        y_clean = self.y_clean.reset_index(drop=True)

        print("æ•°æ®é›†å¤§å°ï¼š ", X_clean.shape, y_clean.shape)
        # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºæ ‡ç­¾ï¼ˆæµ‹è¯•é›†ï¼‰
        if y_clean.isnull().any():
            print("ğŸ“‹ æ£€æµ‹åˆ°ç©ºæ ‡ç­¾ï¼Œå°†å…¶ä½œä¸ºæµ‹è¯•é›†...")
            test_mask = y_clean.isnull()
            self.X_test = X_clean[test_mask].reset_index(drop=True)
            self.y_test = y_clean[test_mask].reset_index(drop=True)

            # å‰©ä½™çš„ä½œä¸ºè®­ç»ƒ+éªŒè¯é›†
            train_val_mask = y_clean.isin([1,0])
            X_train_val = X_clean[train_val_mask].reset_index(drop=True)
            y_train_val = y_clean[train_val_mask].reset_index(drop=True)
        else:
            print("ğŸ“‹ æœªæ£€æµ‹åˆ°ç©ºæ ‡ç­¾ï¼Œä»å®Œæ•´æ•°æ®ä¸­æ‹†åˆ†æµ‹è¯•é›†...")
            # å¦‚æœæ²¡æœ‰ç©ºæ ‡ç­¾ï¼Œåˆ™éšæœºæ‹†åˆ†æµ‹è¯•é›†ï¼ˆ20%ï¼‰
            X_train_val, self.X_test, y_train_val, self.y_test = train_test_split(
                X_clean,
                y_clean,
                test_size=0.2,
                random_state=random_state,
                stratify=y_clean if y_clean.nunique() > 1 else None,
            )

        # ä»è®­ç»ƒ+éªŒè¯é›†ä¸­æ‹†åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        if val_size > 0 and len(X_train_val) > 1:
            try:
                self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(
                    X_train_val,
                    y_train_val,
                    test_size=val_size,
                    random_state=random_state,
                    stratify=y_train_val if y_train_val.nunique() > 1 else None,
                )
            except ValueError as e:
                print(f"âš ï¸ åˆ†å±‚æ‹†åˆ†å¤±è´¥ï¼Œä½¿ç”¨éšæœºæ‹†åˆ†: {e}")
                self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(
                    X_train_val,
                    y_train_val,
                    test_size=val_size,
                    random_state=random_state,
                )
        else:
            # å¦‚æœä¸éœ€è¦éªŒè¯é›†æˆ–æ•°æ®å¤ªå°‘
            self.X_train = X_train_val
            self.y_train = y_train_val
            self.X_val = None
            self.y_val = None

        # æ‰“å°æ‹†åˆ†ç»“æœ
        print(f"âœ… è®­ç»ƒé›†: {self.X_train.shape if self.X_train is not None else 'None'}")
        print(f"âœ… éªŒè¯é›†: {self.X_val.shape if self.X_val is not None else 'None'}")
        print(f"âœ… æµ‹è¯•é›†: {self.X_test.shape if self.X_test is not None else 'None'}")

        # æ‰“å°æ ‡ç­¾åˆ†å¸ƒ
        if self.y_train is not None:
            print(f"è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ:\n{pd.Series(self.y_train).value_counts()}")
        if self.y_val is not None:
            print(f"éªŒè¯é›†æ ‡ç­¾åˆ†å¸ƒ:\n{pd.Series(self.y_val).value_counts()}")

    def transform(self, X):
        """å¯¹æ–°æ•°æ®è¿›è¡Œé¢„å¤„ç†"""
        if self.clean_pipe is None:
            raise ValueError("Pipeline has not been fitted yet.")

        return self.clean_pipe.transform(X)

    def predict(self, X):
        """é¢„æµ‹æ–°æ•°æ®"""
        if not self.is_fitted:
            raise ValueError("Model has not been trained yet.")

        X_processed = self.transform(X)
        return self.model_pipe.predict(X_processed)

    def predict_proba(self, X):
        """é¢„æµ‹æ¦‚ç‡"""
        if not self.is_fitted:
            raise ValueError("Model has not been trained yet.")

        X_processed = self.transform(X)
        return self.model_pipe.predict_proba(X_processed)

    def evaluate(self, stage="val"):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        if not self.is_fitted:
            raise ValueError("Model has not been trained yet.")

        if stage == "val":
            X_eval, y_eval = self.X_val, self.y_val
        elif stage == "test":
            X_eval, y_eval = self.X_test, self.y_test
        elif stage == "train":
            X_eval, y_eval = self.X_train, self.y_train
        else:
            raise ValueError("stage must be 'train', 'val' or 'test'")

        if X_eval is None or y_eval is None:
            print(f"âŒ {stage.upper()} é›†æ•°æ®ä¸å­˜åœ¨")
            return None

        # è¿‡æ»¤æ‰ç©ºæ ‡ç­¾
        mask = y_eval.notna()
        if not mask.any():
            print(f"âŒ {stage.upper()} é›†æ²¡æœ‰æœ‰æ•ˆæ ‡ç­¾")
            return None

        X_eval_clean = X_eval[mask]
        y_eval_clean = y_eval[mask]

        # é¢„æµ‹
        y_pred = self.model_pipe.predict(X_eval_clean)

        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(y_eval_clean, y_pred)

        print(f"ğŸ“Š {stage.upper()} é›†è¯„ä¼°ç»“æœ:")
        print(f"å‡†ç¡®ç‡: {accuracy:.4f}")

        # å¦‚æœæ˜¯äºŒåˆ†ç±»ï¼Œè®¡ç®—AUC
        if hasattr(self.model_pipe, "predict_proba") and len(np.unique(y_eval_clean)) == 2:
            try:
                y_pred_proba = self.model_pipe.predict_proba(X_eval_clean)
                auc = roc_auc_score(y_eval_clean, y_pred_proba[:, 1])
                print(f"AUC: {auc:.4f}")
            except Exception as e:
                print(f"âš ï¸ AUCè®¡ç®—å¤±è´¥: {e}")
                auc = None
        else:
            auc = None

        print(f"\nè¯¦ç»†æŠ¥å‘Š:\n{classification_report(y_eval_clean, y_pred)}")

        return {
            "accuracy": accuracy,
            "auc": auc,
            "y_true": y_eval_clean,
            "y_pred": y_pred,
        }

    def get_feature_importance(self, top_n=20):
        """è·å–ç‰¹å¾é‡è¦æ€§"""
        if not self.is_fitted:
            print("æ¨¡å‹å°šæœªè®­ç»ƒ")
            return None

        # å°è¯•è·å–ç‰¹å¾é‡è¦æ€§
        model = self.model_pipe
        if hasattr(model, "named_steps"):
            # å¦‚æœæ˜¯Pipelineï¼Œè·å–æœ€åä¸€ä¸ªæ­¥éª¤
            final_step = list(model.named_steps.values())[-1]
        else:
            final_step = model

        if hasattr(final_step, "feature_importances_"):
            importances = final_step.feature_importances_
            feature_names = self.X_train.columns

            # åˆ›å»ºç‰¹å¾é‡è¦æ€§DataFrame
            importance_df = pd.DataFrame({"feature": feature_names, "importance": importances}).sort_values(
                "importance", ascending=False
            )

            print(f"ğŸ” Top {top_n} é‡è¦ç‰¹å¾:")
            print(importance_df.head(top_n))

            return importance_df
        else:
            print("æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§åˆ†æ")
            return None

    def summary(self):
        """æ‰“å°ç®¡é“æ‘˜è¦ä¿¡æ¯"""
        print("ğŸ“‹ TCDataPipeline æ‘˜è¦:")
        print(f"æ•°æ®æ¸…æ´—ç®¡é“: {self.clean_pipe is not None}")
        print(f"é‡‡æ ·ç®¡é“: {self.sample_pipe is not None}")
        print(f"æ¨¡å‹ç®¡é“: {self.model_pipe is not None}")
        print(f"æ¨¡å‹å·²è®­ç»ƒ: {self.is_fitted}")

        if self.X_clean is not None:
            print(f"æ¸…æ´—åæ•°æ®å½¢çŠ¶: {self.X_clean.shape}")

        if self.X_train is not None:
            print(f"è®­ç»ƒé›†: {self.X_train.shape}")
        if self.X_val is not None:
            print(f"éªŒè¯é›†: {self.X_val.shape}")
        if self.X_test is not None:
            print(f"æµ‹è¯•é›†: {self.X_test.shape}")


def analysis():
    """Perform data analysis."""
    dataset = load_data()

    print("train f1 info:")
    print(dataset.train_f1.info())
    print("=" * 50)

    print("user f1 info: ")
    print(dataset.user_f1.info())
    print("=" * 50)

    print("log f1 info: ")
    print(dataset.log_f1.info())
    print("=" * 50)

    print("train f2 info: ")
    print(dataset.train_f2.info())
    print("=" * 50)

    print("test f2 info:")
    print(dataset.test_f2.info())
    print("=" * 50)


def run():
    df = load_dataframe()
    X, y = df.drop(columns=["label"]), df["label"]
    pipe = create_clean_pipeline(
        TCDataConfig(
            fill_median_cols=["age_range"],
            fill_mode_cols=["gender"],
        )
    )
    pipe = TCDataPipeline(
        TCDataConfig(
            fill_median_cols=["age_range"],
            fill_mode_cols=["gender"],
            cache_clean_result=True,
            cache_clean_path="../data/cleaned_data.pkl",
        )
    )

    pipe.summary()
    pipe.fit(X, y)
    pipe.evaluate(stage="val")
    print(X.head(10))


if __name__ == "__main__":
    run()
