import gc
import os
import pickle

import numpy as np
import pandas as pd
from scipy.sparse import coo_matrix
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.decomposition import NMF
from sklearn.preprocessing import LabelEncoder


class MatrixTransformer(BaseEstimator, TransformerMixin):
    """åŸºäºçŸ©é˜µåˆ†è§£çš„embeddingç‰¹å¾è½¬æ¢å™¨"""

    def __init__(
        self,
        n_components: int = 50,
        sample_users: int = 100000,
        sample_merchants: int = 5000,
        sample_categories: int = 1000,
        sample_brands: int = 3000,
        min_interactions: int = 2,
        target_date: str = "1111",  # ç›®æ ‡è´­ä¹°è¡Œä¸ºæ—¥æœŸ
        enable_cache: bool = True,
        cache_path: str = "../output/matrix_features.pkl",
        random_state: int = 42,
    ):
        """
        Args:
            n_components: embeddingç»´åº¦
            sample_users: é‡‡æ ·ç”¨æˆ·æ•°é‡
            sample_merchants/categories/brands: é‡‡æ ·å®ä½“æ•°é‡
            min_interactions: æœ€å°äº¤äº’æ¬¡æ•°
            target_date: ç›®æ ‡è´­ä¹°è¡Œä¸ºæ—¥æœŸï¼ˆç”¨äºcat/brandå‘é‡å…³è”ï¼‰
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
            cache_path: ç¼“å­˜è·¯å¾„
            random_state: éšæœºç§å­
        """
        self.n_components = n_components
        self.sample_users = sample_users
        self.sample_merchants = sample_merchants
        self.sample_categories = sample_categories
        self.sample_brands = sample_brands
        self.min_interactions = min_interactions
        self.target_date = target_date
        self.enable_cache = enable_cache
        self.cache_path = cache_path
        self.random_state = random_state

        self.cache_prepare_data = True
        self.cache_prepare_data_path = "./output/matrix_prepare_data.pkl"
        # NMFæ¨¡å‹
        self.nmf_models = {}

        # æ ‡ç­¾ç¼–ç å™¨
        self.label_encoders = {}

        # é‡‡æ ·åçš„å®ä½“é›†åˆ
        self.sampled_entities = {}

        # Embeddingç»“æœ
        self.merchant_embeddings = None  # å•†æˆ·embedding
        self.category_embeddings = None  # ç±»åˆ«embedding
        self.brand_embeddings = None  # å“ç‰Œembedding

        # æ ·æœ¬çº§åˆ«çš„ç‰¹å¾ï¼ˆç”¨äºtransformï¼‰
        self.sample_features = None

        self.is_fitted = False

    def fit(self, X, y=None):
        """è®­ç»ƒçŸ©é˜µåˆ†è§£æ¨¡å‹"""

        # æ£€æŸ¥ç¼“å­˜
        if self.enable_cache and os.path.exists(self.cache_path):
            print(f"â™»ï¸ ä»ç¼“å­˜åŠ è½½çŸ©é˜µåˆ†è§£ç‰¹å¾: {self.cache_path}")
            with open(self.cache_path, "rb") as f:
                cached_data = pickle.load(f)

            self._load_from_cache(cached_data)
            print("âœ… çŸ©é˜µåˆ†è§£ç‰¹å¾åŠ è½½å®Œæˆ")
            self.is_fitted = True
            return self

        print("ğŸ”„ å¼€å§‹è®­ç»ƒçŸ©é˜µåˆ†è§£ç‰¹å¾...")

        # 1. æ•°æ®é¢„å¤„ç†
        df = self._prepare_interaction_data(X)

        # 2. é‡‡æ ·ç­–ç•¥
        sampled_data = self._apply_sampling_strategy(df, y)

        # 3. æ„å»ºäº¤äº’çŸ©é˜µå¹¶è®­ç»ƒNMF
        self._build_and_train_nmf(sampled_data)

        # 4. è®¡ç®—æ ·æœ¬çº§åˆ«çš„ç‰¹å¾
        self._compute_sample_features(X, y)

        # 5. ç¼“å­˜ç»“æœ
        self._cache_results()

        self.is_fitted = True
        print("âœ… çŸ©é˜µåˆ†è§£ç‰¹å¾è®­ç»ƒå®Œæˆ")
        return self

    def transform(self, X):
        """è½¬æ¢æ•°æ®ä¸ºçŸ©é˜µåˆ†è§£ç‰¹å¾"""
        if not self.is_fitted:
            raise ValueError("MatrixTransformer has not been fitted yet.")

        print("ğŸ”„ å¼€å§‹çŸ©é˜µåˆ†è§£ç‰¹å¾è½¬æ¢...")

        result = X.copy()

        # å…³è”å•†æˆ·embeddingï¼ˆç›´æ¥å…³è”ï¼‰
        if self.merchant_embeddings is not None:
            result = result.merge(self.merchant_embeddings, on="merchant_id", how="left")
            print(f"  âœ… å…³è”å•†æˆ·embedding: {self.n_components}ç»´")

        # å…³è”æ ·æœ¬çº§åˆ«çš„cat/brandç‰¹å¾
        if self.sample_features is not None:
            result = result.merge(self.sample_features, on=["user_id", "merchant_id"], how="left")
            cat_dims = len([col for col in self.sample_features.columns if col.startswith("cat_emb")])
            brand_dims = len([col for col in self.sample_features.columns if col.startswith("brand_emb")])
            print(f"  âœ… å…³è”ç±»åˆ«embedding: {cat_dims}ç»´")
            print(f"  âœ… å…³è”å“ç‰Œembedding: {brand_dims}ç»´")

        print(f"âœ… çŸ©é˜µåˆ†è§£ç‰¹å¾è½¬æ¢å®Œæˆï¼Œæ–°å¢ç»´åº¦: {result.shape[1] - X.shape[1]}")
        return result

    def _prepare_interaction_data(self, X):
        """å‡†å¤‡äº¤äº’æ•°æ®"""
        if self.cache_prepare_data and os.path.exists(self.cache_prepare_data_path):
            print(f"â™»ï¸ ä»ç¼“å­˜åŠ è½½äº¤äº’æ•°æ®: {self.cache_prepare_data_path}")
            with open(self.cache_prepare_data_path, "rb") as f:
                df = pickle.load(f)
            print("âœ… äº¤äº’æ•°æ®åŠ è½½å®Œæˆ")
            return df

        print("ğŸ“Š å‡†å¤‡äº¤äº’æ•°æ®...")

        df = X.copy()
        df = df[df["activity_log"].notnull()]

        # å±•å¼€æ´»åŠ¨æ—¥å¿—
        df = df.assign(activity_log=df["activity_log"].str.split("#")).explode("activity_log")
        split_columns = ["item_id", "cate_id", "brand_id", "time", "action_type"]
        df[split_columns] = df["activity_log"].str.split(":", expand=True)

        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        df = df.dropna(subset=["cate_id", "brand_id", "action_type"])

        print(f"âœ… äº¤äº’æ•°æ®å‡†å¤‡å®Œæˆ: {len(df)} æ¡è®°å½•")
        if self.cache_prepare_data:
            with open(self.cache_prepare_data_path, "wb") as f:
                pickle.dump(df, f)
            print(f"ğŸ’¾ äº¤äº’æ•°æ®å·²ç¼“å­˜: {self.cache_prepare_data_path}")
        return df

    def _apply_sampling_strategy(self, df, y):
        """åº”ç”¨é‡‡æ ·ç­–ç•¥"""
        print("ğŸ² åº”ç”¨é‡‡æ ·ç­–ç•¥...")

        # # ç¡®å®šè®­ç»ƒæ•°æ®èŒƒå›´
        # if y is not None:
        #     train_mask = y != -1
        #     train_user_merchant = df[df.index.isin(df.index[train_mask])][["user_id", "merchant_id"]].drop_duplicates()
        # else:
        #     train_user_merchant = df[["user_id", "merchant_id"]].drop_duplicates()

        # ç»Ÿè®¡äº¤äº’é¢‘æ¬¡
        user_interactions = df.groupby("user_id").size()
        merchant_interactions = df.groupby("merchant_id").size()
        category_interactions = df.groupby("cate_id").size()
        brand_interactions = df.groupby("brand_id").size()

        # é‡‡æ ·æ´»è·ƒç”¨æˆ·
        active_users = user_interactions[user_interactions >= self.min_interactions]
        if len(active_users) > self.sample_users:
            # æŒ‰æ´»è·ƒåº¦åŠ æƒé‡‡æ ·
            user_probs = active_users / active_users.sum()
            np.random.seed(self.random_state)
            sampled_users = np.random.choice(active_users.index, size=self.sample_users, replace=False, p=user_probs)
        else:
            sampled_users = active_users.index

        # é‡‡æ ·çƒ­é—¨å®ä½“
        popular_merchants = merchant_interactions.nlargest(self.sample_merchants).index
        popular_categories = category_interactions.nlargest(self.sample_categories).index
        popular_brands = brand_interactions.nlargest(self.sample_brands).index

        # è¿‡æ»¤é‡‡æ ·åçš„æ•°æ®
        sampled_df = df[
            (df["user_id"].isin(sampled_users))
            & (df["merchant_id"].isin(popular_merchants))
            & (df["cate_id"].isin(popular_categories))
            & (df["brand_id"].isin(popular_brands))
        ].copy()

        # å­˜å‚¨é‡‡æ ·ç»“æœ
        self.sampled_entities = {
            "users": set(sampled_users),
            "merchants": set(popular_merchants),
            "categories": set(popular_categories),
            "brands": set(popular_brands),
        }

        print(f"  âœ… é‡‡æ ·ç»“æœ: {len(sampled_users)} ç”¨æˆ·, {len(popular_merchants)} å•†æˆ·")
        print(f"           {len(popular_categories)} ç±»åˆ«, {len(popular_brands)} å“ç‰Œ")
        print(f"  âœ… é‡‡æ ·åæ•°æ®: {len(sampled_df)} æ¡äº¤äº’è®°å½•")

        return sampled_df

    def _build_and_train_nmf(self, sampled_df):
        """æ„å»ºäº¤äº’çŸ©é˜µå¹¶è®­ç»ƒNMFæ¨¡å‹"""
        print("ğŸ¤– æ„å»ºäº¤äº’çŸ©é˜µå¹¶è®­ç»ƒNMFæ¨¡å‹...")

        # ä¸ºæ¯ç§å®ä½“ç±»å‹æ„å»ºç”¨æˆ·-å®ä½“äº¤äº’çŸ©é˜µ
        entity_types = [
            ("merchant", "merchant_id"),
            ("category", "cate_id"),
            ("brand", "brand_id"),
        ]

        for entity_name, entity_column in entity_types:
            print(f"  ğŸ”„ è®­ç»ƒ{entity_name} NMFæ¨¡å‹...")

            # ç»Ÿè®¡äº¤äº’æ¬¡æ•°
            interaction_counts = sampled_df.groupby(["user_id", entity_column]).size().reset_index(name="count")

            # åˆ›å»ºæ ‡ç­¾ç¼–ç å™¨
            user_encoder = LabelEncoder()
            entity_encoder = LabelEncoder()

            # ç¼–ç ç”¨æˆ·å’Œå®ä½“ID
            interaction_counts["user_idx"] = user_encoder.fit_transform(interaction_counts["user_id"])
            interaction_counts["entity_idx"] = entity_encoder.fit_transform(interaction_counts[entity_column])

            # å­˜å‚¨ç¼–ç å™¨
            self.label_encoders[entity_name] = {
                "user_encoder": user_encoder,
                "entity_encoder": entity_encoder,
            }

            # æ„å»ºç¨€ç–äº¤äº’çŸ©é˜µ
            n_users = len(user_encoder.classes_)
            n_entities = len(entity_encoder.classes_)

            interaction_matrix = coo_matrix(
                (
                    interaction_counts["count"],
                    (interaction_counts["user_idx"], interaction_counts["entity_idx"]),
                ),
                shape=(n_users, n_entities),
            ).tocsr()

            print(f"    ğŸ“Š {entity_name}äº¤äº’çŸ©é˜µå½¢çŠ¶: {interaction_matrix.shape}")
            print(f"    ğŸ“Š ç¨€ç–åº¦: {1 - interaction_matrix.nnz / (n_users * n_entities):.4f}")

            # è®­ç»ƒNMFæ¨¡å‹
            nmf_model = NMF(
                n_components=self.n_components,
                random_state=self.random_state,
                max_iter=200,
                alpha_W=0.01,  # æ–°ç‰ˆæœ¬å‚æ•°
                alpha_H=0.01,  # æ–°ç‰ˆæœ¬å‚æ•°
                init="random",
            )

            # çŸ©é˜µåˆ†è§£ï¼šW (ç”¨æˆ·embedding) Ã— H (å®ä½“embedding)
            user_embeddings = nmf_model.fit_transform(interaction_matrix)
            entity_embeddings = nmf_model.components_.T

            # å­˜å‚¨æ¨¡å‹
            self.nmf_models[entity_name] = nmf_model

            # åˆ›å»ºå®ä½“embedding DataFrame
            if entity_name == "merchant":
                # å•†æˆ·embeddingç›´æ¥å­˜å‚¨
                entity_emb_columns = [f"merchant_emb_{i}" for i in range(self.n_components)]
                self.merchant_embeddings = pd.DataFrame(entity_embeddings, columns=entity_emb_columns)
                self.merchant_embeddings["merchant_id"] = entity_encoder.classes_

            elif entity_name == "category":
                # ç±»åˆ«embeddingå­˜å‚¨ï¼Œåç»­ç”¨äºæ ·æœ¬å…³è”
                entity_emb_columns = [f"cat_emb_{i}" for i in range(self.n_components)]
                self.category_embeddings = pd.DataFrame(entity_embeddings, columns=entity_emb_columns)
                self.category_embeddings["cate_id"] = entity_encoder.classes_

            elif entity_name == "brand":
                # å“ç‰Œembeddingå­˜å‚¨ï¼Œåç»­ç”¨äºæ ·æœ¬å…³è”
                entity_emb_columns = [f"brand_emb_{i}" for i in range(self.n_components)]
                self.brand_embeddings = pd.DataFrame(entity_embeddings, columns=entity_emb_columns)
                self.brand_embeddings["brand_id"] = entity_encoder.classes_

            print(f"    âœ… {entity_name} NMFæ¨¡å‹è®­ç»ƒå®Œæˆ")

            # æ¸…ç†å†…å­˜
            del interaction_matrix, user_embeddings, entity_embeddings
            gc.collect()

    def _compute_sample_features(self, X, y):
        """è®¡ç®—æ ·æœ¬çº§åˆ«çš„cat/brandç‰¹å¾"""
        print("ğŸ”„ è®¡ç®—æ ·æœ¬çº§åˆ«çš„cat/brandç‰¹å¾...")

        # ç¡®å®šéœ€è¦å¤„ç†çš„æ ·æœ¬
        if y is not None:
            valid_mask = y != -1
            valid_samples = X[valid_mask][["user_id", "merchant_id"]].copy()
        else:
            valid_samples = X[["user_id", "merchant_id"]].copy()

        valid_samples = valid_samples.drop_duplicates()

        # å‡†å¤‡ç›®æ ‡æ—¥æœŸçš„è´­ä¹°è¡Œä¸ºæ•°æ®
        df = self._prepare_interaction_data(X)

        # è¿‡æ»¤ç›®æ ‡æ—¥æœŸçš„è´­ä¹°è¡Œä¸ºï¼ˆaction_type=1è¡¨ç¤ºè´­ä¹°ï¼‰
        target_purchases = df[(df["time"].str.contains(self.target_date, na=False)) & (df["action_type"] == "1")].copy()

        print(f"  ğŸ“Š ç›®æ ‡æ—¥æœŸ({self.target_date})è´­ä¹°è¡Œä¸º: {len(target_purchases)} æ¡")

        sample_features_list = []

        for _, row in valid_samples.iterrows():
            user_id = row["user_id"]
            merchant_id = row["merchant_id"]

            # è·å–è¯¥ç”¨æˆ·åœ¨ç›®æ ‡å•†æˆ·åœ¨ç›®æ ‡æ—¥æœŸçš„è´­ä¹°è¡Œä¸º
            user_merchant_purchases = target_purchases[
                (target_purchases["user_id"] == user_id) & (target_purchases["merchant_id"] == merchant_id)
            ]

            # åˆå§‹åŒ–ç‰¹å¾
            sample_feature = {
                "user_id": user_id,
                "merchant_id": merchant_id,
            }

            # Cat embeddingå‡å€¼
            if len(user_merchant_purchases) > 0 and self.category_embeddings is not None:
                purchase_cats = user_merchant_purchases["cate_id"].unique()
                cat_embeddings = self.category_embeddings[self.category_embeddings["cate_id"].isin(purchase_cats)]

                if len(cat_embeddings) > 0:
                    # è®¡ç®—å‡å€¼
                    cat_emb_cols = [col for col in cat_embeddings.columns if col.startswith("cat_emb")]
                    cat_mean = cat_embeddings[cat_emb_cols].mean()
                    sample_feature.update(cat_mean.to_dict())
                else:
                    # å¡«å……é›¶å‘é‡
                    for i in range(self.n_components):
                        sample_feature[f"cat_emb_{i}"] = 0.0
            else:
                # å¡«å……é›¶å‘é‡
                for i in range(self.n_components):
                    sample_feature[f"cat_emb_{i}"] = 0.0

            # Brand embeddingå‡å€¼
            if len(user_merchant_purchases) > 0 and self.brand_embeddings is not None:
                purchase_brands = user_merchant_purchases["brand_id"].unique()
                brand_embeddings = self.brand_embeddings[self.brand_embeddings["brand_id"].isin(purchase_brands)]

                if len(brand_embeddings) > 0:
                    # è®¡ç®—å‡å€¼
                    brand_emb_cols = [col for col in brand_embeddings.columns if col.startswith("brand_emb")]
                    brand_mean = brand_embeddings[brand_emb_cols].mean()
                    sample_feature.update(brand_mean.to_dict())
                else:
                    # å¡«å……é›¶å‘é‡
                    for i in range(self.n_components):
                        sample_feature[f"brand_emb_{i}"] = 0.0
            else:
                # å¡«å……é›¶å‘é‡
                for i in range(self.n_components):
                    sample_feature[f"brand_emb_{i}"] = 0.0

            sample_features_list.append(sample_feature)

        # è½¬æ¢ä¸ºDataFrame
        self.sample_features = pd.DataFrame(sample_features_list)

        print(f"  âœ… æ ·æœ¬ç‰¹å¾è®¡ç®—å®Œæˆ: {len(self.sample_features)} ä¸ªæ ·æœ¬")

    def _load_from_cache(self, cached_data):
        """ä»ç¼“å­˜åŠ è½½æ•°æ®"""
        self.merchant_embeddings = cached_data.get("merchant_embeddings", None)
        self.category_embeddings = cached_data.get("category_embeddings", None)
        self.brand_embeddings = cached_data.get("brand_embeddings", None)
        self.sample_features = cached_data.get("sample_features", None)
        self.sampled_entities = cached_data.get("sampled_entities", {})
        self.label_encoders = cached_data.get("label_encoders", {})

    def _cache_results(self):
        """ç¼“å­˜ç»“æœ"""
        if self.enable_cache:
            print("ğŸ’¾ ç¼“å­˜çŸ©é˜µåˆ†è§£ç‰¹å¾...")
            os.makedirs(os.path.dirname(self.cache_path), exist_ok=True)

            cached_data = {
                "merchant_embeddings": self.merchant_embeddings,
                "category_embeddings": self.category_embeddings,
                "brand_embeddings": self.brand_embeddings,
                "sample_features": self.sample_features,
                "sampled_entities": self.sampled_entities,
                "label_encoders": self.label_encoders,
            }

            with open(self.cache_path, "wb") as f:
                pickle.dump(cached_data, f)
            print(f"âœ… ç‰¹å¾å·²ç¼“å­˜åˆ°: {self.cache_path}")

    def get_embedding_stats(self):
        """è·å–embeddingç»Ÿè®¡ä¿¡æ¯"""
        if not self.is_fitted:
            return None

        stats = {
            "merchant_embeddings": self.merchant_embeddings.shape if self.merchant_embeddings is not None else None,
            "category_embeddings": self.category_embeddings.shape if self.category_embeddings is not None else None,
            "brand_embeddings": self.brand_embeddings.shape if self.brand_embeddings is not None else None,
            "sample_features": self.sample_features.shape if self.sample_features is not None else None,
            "sampled_entities": {k: len(v) for k, v in self.sampled_entities.items()},
        }

        return stats

    def get_feature_names(self):
        """è·å–æ‰€æœ‰ç‰¹å¾åç§°"""
        if not self.is_fitted:
            raise ValueError("Transformer has not been fitted yet.")

        feature_names = []

        # å•†æˆ·embeddingç‰¹å¾å
        if self.merchant_embeddings is not None:
            feature_names.extend([col for col in self.merchant_embeddings.columns if col != "merchant_id"])

        # æ ·æœ¬çº§åˆ«çš„cat/brandç‰¹å¾å
        if self.sample_features is not None:
            feature_names.extend([col for col in self.sample_features.columns if col not in ["user_id", "merchant_id"]])

        return feature_names


if __name__ == "__main__":
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    import numpy as np

    np.random.seed(42)
    n_samples = 1000

    test_data = {
        "user_id": np.random.randint(1, 100, n_samples),
        "merchant_id": np.random.randint(1, 50, n_samples),
        "activity_log": [
            f"item_{np.random.randint(1, 500)}:cat_{np.random.randint(1, 20)}:brand_{np.random.randint(1, 30)}:1111:1#"
            + f"item_{np.random.randint(1, 500)}:cat_{np.random.randint(1, 20)}:brand_{np.random.randint(1, 30)}:1112:2"
            for _ in range(n_samples)
        ],
    }

    df = pd.DataFrame(test_data)
    X = df
    y = np.random.randint(-1, 2, n_samples)  # -1è¡¨ç¤ºæµ‹è¯•é›†ï¼Œ0/1è¡¨ç¤ºè®­ç»ƒé›†æ ‡ç­¾

    print("ğŸ§ª ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•...")
    print(f"æ¨¡æ‹Ÿæ•°æ®å½¢çŠ¶: {X.shape}")

    transformer = MatrixTransformer(
        n_components=20,
        sample_users=50,
        sample_merchants=30,
        sample_categories=15,
        sample_brands=20,
        target_date="1111",
        enable_cache=False,
    )
    transformer.fit(X, y)

    transformed_df = transformer.transform(X)
    print(f"è½¬æ¢åçš„æ•°æ®å½¢çŠ¶: {transformed_df.shape}")
    print(f"ç‰¹å¾ç»Ÿè®¡: {transformer.get_embedding_stats()}")
    print(f"ç‰¹å¾åç§°: {transformer.get_feature_names()}")
    print(f"è½¬æ¢åçš„æ•°æ®é¢„è§ˆ:\n{transformed_df.head()}")
