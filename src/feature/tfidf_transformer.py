import gc
import os
import pickle

import pandas as pd
from scipy.sparse import csr_matrix, hstack
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.feature_extraction.text import TfidfVectorizer


class TfidfTransformer(BaseEstimator, TransformerMixin):
    """TF-IDFç‰¹å¾è½¬æ¢å™¨"""

    def __init__(
        self,
        top_n_features=50,
        min_df=1,
        max_df=0.95,
        enable_cache=True,
        cache_path: str = "../output/tfidf_feature.pkl",
    ):
        """
        Args:
            top_n_features: æ¯ä¸ªç‰¹å¾ç±»å‹ä¿ç•™çš„æœ€å¤§ç‰¹å¾æ•°
            min_df: æœ€å°æ–‡æ¡£é¢‘ç‡ï¼Œè¿‡æ»¤ä½é¢‘ç‰¹å¾
            max_df: æœ€å¤§æ–‡æ¡£é¢‘ç‡ï¼Œè¿‡æ»¤é«˜é¢‘ç‰¹å¾
        """
        self.top_n_features = top_n_features
        self.min_df = min_df
        self.max_df = max_df
        self.enable_cache = enable_cache
        self.cache_path = cache_path

        # ç”¨æˆ·ç‰¹å¾çš„TF-IDFå‘é‡åŒ–å™¨
        self.user_vectorizers = {
            "cat": TfidfVectorizer(max_features=top_n_features, min_df=min_df, max_df=max_df),
            "brand": TfidfVectorizer(max_features=top_n_features, min_df=min_df, max_df=max_df),
            "item": TfidfVectorizer(max_features=top_n_features, min_df=min_df, max_df=max_df),
            "merchant": TfidfVectorizer(max_features=top_n_features, min_df=min_df, max_df=max_df),
        }

        # å•†æˆ·ç‰¹å¾çš„TF-IDFå‘é‡åŒ–å™¨
        self.merchant_vectorizers = {
            "cat": TfidfVectorizer(max_features=top_n_features, min_df=min_df, max_df=max_df),
            "brand": TfidfVectorizer(max_features=top_n_features, min_df=min_df, max_df=max_df),
            "item": TfidfVectorizer(max_features=top_n_features, min_df=min_df, max_df=max_df),
            "user": TfidfVectorizer(max_features=top_n_features, min_df=min_df, max_df=max_df),
        }

        # ç”¨æˆ·-å•†æˆ·äº¤äº’ç‰¹å¾çš„TF-IDFå‘é‡åŒ–å™¨
        self.user_merchant_vectorizers = {
            "cat": TfidfVectorizer(max_features=top_n_features, min_df=min_df, max_df=max_df),
            "brand": TfidfVectorizer(max_features=top_n_features, min_df=min_df, max_df=max_df),
            "item": TfidfVectorizer(max_features=top_n_features, min_df=min_df, max_df=max_df),
        }

        # å­˜å‚¨é¢„è®¡ç®—çš„ç‰¹å¾çŸ©é˜µ
        self.user_tfidf_features = None
        self.merchant_tfidf_features = None
        self.user_merchant_tfidf_features = None

        self.is_fitted = False

    def fit(self, X, y=None):
        """è®­ç»ƒTF-IDFå‘é‡åŒ–å™¨å¹¶é¢„è®¡ç®—æ‰€æœ‰ç‰¹å¾"""

        # æ£€æŸ¥ç¼“å­˜
        if self.enable_cache and os.path.exists(self.cache_path):
            print(f"â™»ï¸ ä»ç¼“å­˜åŠ è½½TF-IDFç‰¹å¾: {self.cache_path}")
            with open(self.cache_path, "rb") as f:
                cached_data = pickle.load(f)

            self.user_tfidf_features = cached_data.get("user_tfidf_features", None)
            self.merchant_tfidf_features = cached_data.get("merchant_tfidf_features", None)
            self.user_merchant_tfidf_features = cached_data.get("user_merchant_tfidf_features", None)

            print("âœ… TF-IDFç‰¹å¾åŠ è½½å®Œæˆ")
            self.is_fitted = True
            return self

        print("ğŸ”„ å¼€å§‹è®­ç»ƒTF-IDFç‰¹å¾...")

        # 1. æ•°æ®é¢„å¤„ç†å’Œå±•å¼€
        df = self._prepare_data(X)

        # 2. æ„å»ºæ‰€æœ‰æ–‡æ¡£
        print("ğŸ“ æ„å»ºæ–‡æ¡£...")
        user_docs = self._build_user_documents(df)
        merchant_docs = self._build_merchant_documents(df)
        user_merchant_docs = self._build_user_merchant_documents(df)

        # 3. è®­ç»ƒå‘é‡åŒ–å™¨
        print("ğŸ¤– è®­ç»ƒå‘é‡åŒ–å™¨...")
        self._fit_vectorizers(user_docs, merchant_docs, user_merchant_docs)

        # 4. è®¡ç®—éœ€è¦ä¿å­˜ç‰¹å¾çš„userï¼Œ merchant_id
        print("ğŸ†” è®¡ç®—éœ€è¦ä¿å­˜ç‰¹å¾çš„ID...")
        train_test_mask = y != -1
        valid_df = X.loc[train_test_mask, ["user_id", "merchant_id"]]

        user_ids = valid_df["user_id"].unique()
        merchant_ids = valid_df["merchant_id"].unique()
        user_merchant_pairs = set(map(tuple, valid_df[["user_id", "merchant_id"]].values))
        # 4. é¢„è®¡ç®—æ‰€æœ‰ç‰¹å¾çŸ©é˜µ
        print("ğŸ“Š é¢„è®¡ç®—ç‰¹å¾çŸ©é˜µ...")
        self.user_tfidf_features = self._compute_user_features(user_docs, user_ids)
        self.merchant_tfidf_features = self._compute_merchant_features(merchant_docs, merchant_ids)
        self.user_merchant_tfidf_features = self._compute_user_merchant_features(
            user_merchant_docs, user_merchant_pairs
        )

        self.is_fitted = True
        print("âœ… TF-IDFç‰¹å¾è®­ç»ƒå®Œæˆ")

        # 5. ç¼“å­˜ç‰¹å¾
        if self.enable_cache:
            print("ğŸ’¾ ç¼“å­˜TF-IDFç‰¹å¾...")
            os.makedirs(os.path.dirname(self.cache_path), exist_ok=True)
            cached_data = {
                "user_tfidf_features": self.user_tfidf_features,
                "merchant_tfidf_features": self.merchant_tfidf_features,
                "user_merchant_tfidf_features": self.user_merchant_tfidf_features,
            }
            with open(self.cache_path, "wb") as f:
                pickle.dump(cached_data, f)
            print(f"âœ… ç‰¹å¾å·²ç¼“å­˜åˆ°: {self.cache_path}")

        # æ¸…ç†å†…å­˜
        del df, user_docs, merchant_docs, user_merchant_docs
        gc.collect()

        return self

    def transform(self, X):
        """é€šè¿‡å…³è”é¢„è®¡ç®—çš„ç‰¹å¾çŸ©é˜µæ¥è½¬æ¢æ•°æ®"""
        if not self.is_fitted:
            raise ValueError("TfidfFeatureTransformer has not been fitted yet.")

        print("ğŸ”„ å¼€å§‹TF-IDFç‰¹å¾è½¬æ¢...")

        df = X.copy()
        # 1. å…³è”ç”¨æˆ·TF-IDFç‰¹å¾
        if self.user_tfidf_features is not None:
            df = df.merge(self.user_tfidf_features, on="user_id", how="left")
            print(f"  âœ… å…³è”ç”¨æˆ·TF-IDFç‰¹å¾: {self.user_tfidf_features.shape[1] - 1} ç»´")

        # 2. å…³è”å•†æˆ·TF-IDFç‰¹å¾
        if self.merchant_tfidf_features is not None:
            df = df.merge(self.merchant_tfidf_features, on="merchant_id", how="left")
            print(f"  âœ… å…³è”å•†æˆ·TF-IDFç‰¹å¾: {self.merchant_tfidf_features.shape[1] - 1} ç»´")

        # 3. å…³è”ç”¨æˆ·-å•†æˆ·äº¤äº’TF-IDFç‰¹å¾
        if self.user_merchant_tfidf_features is not None:
            df = df.merge(self.user_merchant_tfidf_features, on=["user_id", "merchant_id"], how="left")
            print(f"  âœ… å…³è”ç”¨æˆ·-å•†æˆ·TF-IDFç‰¹å¾: {self.user_merchant_tfidf_features.shape[1] - 2} ç»´")

        # 4. ç§»é™¤ä¸éœ€è¦çš„åˆ—
        drop_cols = ["activity_log"]
        df = df.drop(columns=[col for col in drop_cols if col in df.columns])

        print(f"âœ… TF-IDFç‰¹å¾è½¬æ¢å®Œæˆï¼Œæœ€ç»ˆç‰¹å¾ç»´åº¦: {df.shape[1]}")
        return df

    def _prepare_data(self, X):
        """å‡†å¤‡å’Œå±•å¼€æ•°æ®"""
        df = X.copy()
        df = df[df["activity_log"].notnull()]
        df = df.assign(activity_log=df["activity_log"].str.split("#")).explode("activity_log")

        split_columns = ["item_id", "cate_id", "brand_id", "time", "action_type"]
        df[split_columns] = df["activity_log"].str.split(":", expand=True)

        df = df.drop(columns=["activity_log"], errors="ignore")
        print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå±•å¼€åæ•°æ®å½¢çŠ¶: {df.shape}")
        return df

    def _build_user_documents(self, df):
        """æ„å»ºç”¨æˆ·è¡Œä¸ºæ–‡æ¡£"""
        user_docs = {}

        for feature_type, column in [
            ("cat", "cate_id"),
            ("brand", "brand_id"),
            ("item", "item_id"),
            ("merchant", "merchant_id"),
        ]:
            user_grouped = df.groupby("user_id")[column].apply(lambda x: " ".join(x.astype(str).tolist())).to_dict()
            user_docs[feature_type] = user_grouped
            print(f"  ğŸ”¤ æ„å»ºç”¨æˆ·{feature_type}æ–‡æ¡£: å…±è®¡ {len(user_grouped)} ä¸ªç”¨æˆ·")

        return user_docs

    def _build_merchant_documents(self, df):
        """æ„å»ºå•†æˆ·äº¤äº’æ–‡æ¡£"""
        merchant_docs = {}

        for feature_type, column in [
            ("cat", "cate_id"),
            ("brand", "brand_id"),
            ("item", "item_id"),
            # ("user", "user_id"),
        ]:
            merchant_grouped = (
                df.groupby("merchant_id")[column].apply(lambda x: " ".join(x.astype(str).tolist())).to_dict()
            )
            merchant_docs[feature_type] = merchant_grouped
            print(f"  ğŸª æ„å»ºå•†æˆ·{feature_type}æ–‡æ¡£: å…±è®¡ {len(merchant_grouped)} ä¸ªå•†æˆ·")
        return merchant_docs

    def _build_user_merchant_documents(self, df):
        """æ„å»ºç”¨æˆ·-å•†æˆ·äº¤äº’æ–‡æ¡£"""
        user_merchant_docs = {}

        for feature_type, column in [("cat", "cate_id"), ("brand", "brand_id"), ("item", "item_id")]:
            user_merchant_grouped = df.groupby(["user_id", "merchant_id"])[column].apply(
                lambda x: " ".join(x.astype(str).tolist())
            )

            # è½¬æ¢ä¸ºå­—å…¸ï¼Œé”®ä¸º "user_id_merchant_id"
            user_merchant_dict = {}
            for (user_id, merchant_id), doc in user_merchant_grouped.items():
                key = f"{user_id}_{merchant_id}"
                user_merchant_dict[key] = doc

            user_merchant_docs[feature_type] = user_merchant_dict
            print(f"  ğŸ¤ æ„å»ºç”¨æˆ·-å•†æˆ·{feature_type}æ–‡æ¡£: å…±è®¡ {len(user_merchant_dict)} ä¸ªå¯¹")

        return user_merchant_docs

    def _fit_vectorizers(self, user_docs, merchant_docs, user_merchant_docs):
        """è®­ç»ƒæ‰€æœ‰å‘é‡åŒ–å™¨"""
        # è®­ç»ƒç”¨æˆ·å‘é‡åŒ–å™¨
        for feature_type in ["cat", "brand", "item", "merchant"]:
            print(f"  ğŸ”¤ è®­ç»ƒç”¨æˆ·{feature_type}å‘é‡åŒ–å™¨...")
            docs = list(user_docs[feature_type].values())
            if docs:
                self.user_vectorizers[feature_type].fit(docs)

        # è®­ç»ƒå•†æˆ·å‘é‡åŒ–å™¨
        for feature_type in ["cat", "brand", "item"]:
            print(f"  ğŸª è®­ç»ƒå•†æˆ·{feature_type}å‘é‡åŒ–å™¨...")
            docs = list(merchant_docs[feature_type].values())
            if docs:
                self.merchant_vectorizers[feature_type].fit(docs)

        # è®­ç»ƒç”¨æˆ·-å•†æˆ·äº¤äº’å‘é‡åŒ–å™¨
        for feature_type in ["cat", "brand", "item"]:
            print(f"  ğŸ¤ è®­ç»ƒç”¨æˆ·-å•†æˆ·{feature_type}å‘é‡åŒ–å™¨...")
            docs = list(user_merchant_docs[feature_type].values())
            if docs:
                self.user_merchant_vectorizers[feature_type].fit(docs)

    def _compute_user_features(self, user_docs, user_ids):
        """é¢„è®¡ç®—æ‰€æœ‰ç”¨æˆ·çš„TF-IDFç‰¹å¾"""
        print("  ğŸ“Š è®¡ç®—ç”¨æˆ·TF-IDFç‰¹å¾...")

        # all_user_ids = set()
        # for feature_type in ["cat", "brand", "item", "merchant"]:
        #     all_user_ids.update(user_docs[feature_type].keys())

        all_user_ids = sorted(list(user_ids))

        # ä¸ºæ¯ç§ç‰¹å¾ç±»å‹è®¡ç®—TF-IDF
        user_features = []
        feature_names = ["user_id"]

        for feature_type in ["cat", "brand", "item", "merchant"]:
            vectorizer = self.user_vectorizers[feature_type]

            # å‡†å¤‡æ–‡æ¡£åˆ—è¡¨
            docs = [user_docs[feature_type].get(user_id, "") for user_id in all_user_ids]

            if any(docs):
                try:
                    tfidf_matrix = vectorizer.transform(docs)
                    # è½¬æ¢ä¸ºDataFrame
                    n_features = tfidf_matrix.shape[1]
                    columns = [f"user_{feature_type}_tfidf_{i}" for i in range(n_features)]
                    feature_names.extend(columns)
                    user_features.append(tfidf_matrix.toarray())
                except Exception as e:
                    print(f"âš ï¸ ç”¨æˆ·{feature_type}ç‰¹å¾è®¡ç®—å¤±è´¥: {e}")

        if user_features:
            # åˆå¹¶æ‰€æœ‰ç‰¹å¾
            combined_features = pd.DataFrame(
                index=all_user_ids,
                data=hstack([csr_matrix(feat) for feat in user_features]).toarray(),
                columns=feature_names[1:],  # æ’é™¤user_idåˆ—
            )
            combined_features.reset_index(inplace=True)
            combined_features.rename(columns={"index": "user_id"}, inplace=True)
            return combined_features
        else:
            return pd.DataFrame({"user_id": all_user_ids})

    def _compute_merchant_features(self, merchant_docs, merchant_ids):
        """é¢„è®¡ç®—æ‰€æœ‰å•†æˆ·çš„TF-IDFç‰¹å¾"""
        print("  ğŸª è®¡ç®—å•†æˆ·TF-IDFç‰¹å¾...")

        # all_merchant_ids = set()
        # for feature_type in ["cat", "brand", "item"]:
        #     all_merchant_ids.update(merchant_docs[feature_type].keys())

        all_merchant_ids = sorted(list(merchant_ids))

        merchant_features = []
        feature_names = ["merchant_id"]

        for feature_type in ["cat", "brand", "item"]:
            vectorizer = self.merchant_vectorizers[feature_type]

            docs = [merchant_docs[feature_type].get(merchant_id, "") for merchant_id in all_merchant_ids]

            if any(docs):
                try:
                    tfidf_matrix = vectorizer.transform(docs)
                    n_features = tfidf_matrix.shape[1]
                    columns = [f"merchant_{feature_type}_tfidf_{i}" for i in range(n_features)]
                    feature_names.extend(columns)
                    merchant_features.append(tfidf_matrix.toarray())
                except Exception as e:
                    print(f"âš ï¸ å•†æˆ·{feature_type}ç‰¹å¾è®¡ç®—å¤±è´¥: {e}")

        if merchant_features:
            combined_features = pd.DataFrame(
                index=all_merchant_ids,
                data=hstack([csr_matrix(feat) for feat in merchant_features]).toarray(),
                columns=feature_names[1:],
            )
            combined_features.reset_index(inplace=True)
            combined_features.rename(columns={"index": "merchant_id"}, inplace=True)
            return combined_features
        else:
            return pd.DataFrame({"merchant_id": all_merchant_ids})

    def _compute_user_merchant_features(self, user_merchant_docs, user_merchant_pairs):
        print("  ğŸ¤ è®¡ç®—ç”¨æˆ·-å•†æˆ·TF-IDFç‰¹å¾...")

        # åªå¤„ç† user_merchant_pairs ä¸­çš„æœ‰æ•ˆå¯¹
        all_pairs = sorted(list(user_merchant_pairs))
        result_df = pd.DataFrame(all_pairs, columns=["user_id", "merchant_id"])

        for feature_type in ["cat", "brand", "item"]:
            vectorizer = self.user_merchant_vectorizers[feature_type]
            docs = []
            pairs = []
            for user_id, merchant_id in all_pairs:
                key = f"{user_id}_{merchant_id}"
                doc = user_merchant_docs[feature_type].get(key, "")
                if doc:  # åªå¯¹æœ‰å†…å®¹çš„å¯¹åšTF-IDF
                    docs.append(doc)
                    pairs.append((user_id, merchant_id))
            if docs:
                try:
                    tfidf_matrix = vectorizer.transform(docs)
                    n_features = tfidf_matrix.shape[1]
                    columns = [f"user_merchant_{feature_type}_tfidf_{i}" for i in range(n_features)]
                    feat_df = pd.DataFrame(tfidf_matrix.toarray(), columns=columns)
                    feat_df["user_id"] = [p[0] for p in pairs]
                    feat_df["merchant_id"] = [p[1] for p in pairs]
                    result_df = result_df.merge(feat_df, on=["user_id", "merchant_id"], how="left")
                except Exception as e:
                    print(f"âš ï¸ ç”¨æˆ·-å•†æˆ·{feature_type}ç‰¹å¾è®¡ç®—å¤±è´¥: {e}")

        return result_df

    def _compute_user_merchant_features2(self, user_merchant_docs, user_merchant_pairs):
        """é¢„è®¡ç®—æ‰€æœ‰ç”¨æˆ·-å•†æˆ·å¯¹çš„TF-IDFç‰¹å¾"""
        print("  ğŸ¤ è®¡ç®—ç”¨æˆ·-å•†æˆ·TF-IDFç‰¹å¾...")

        # æ”¶é›†æ‰€æœ‰æœ‰å†…å®¹çš„å¯¹
        all_pairs = sorted(list(user_merchant_pairs))
        pair_features = {}

        for feature_type in ["cat", "brand", "item"]:
            vectorizer = self.user_merchant_vectorizers[feature_type]
            # docs = []
            # pairs = []
            # for key, doc in user_merchant_docs[feature_type].items():
            #     if doc:
            #         user_id, merchant_id = key.split("_", 1)
            #         user_id, merchant_id = int(user_id), int(merchant_id)
            #         docs.append(doc)
            #         pairs.append((user_id, merchant_id))
            #         all_pairs.add((user_id, merchant_id))

            print(f"  ğŸ”¤ è®¡ç®—ç”¨æˆ·-å•†æˆ·{feature_type}ç‰¹å¾: å…±è®¡ {len(all_pairs)} ä¸ªæœ‰æ•ˆå¯¹")
            docs = [user_merchant_docs[feature_type].get(f"{u}_{m}", "") for u, m in all_pairs]
            if docs:
                try:
                    tfidf_matrix = vectorizer.transform(docs)
                    n_features = tfidf_matrix.shape[1]
                    columns = [f"user_merchant_{feature_type}_tfidf_{i}" for i in range(n_features)]
                    # ä¿å­˜æ¯ä¸ªç‰¹å¾ç±»å‹çš„ DataFrame
                    pair_features[feature_type] = pd.DataFrame(tfidf_matrix.toarray(), columns=columns)
                    pair_features[feature_type]["user_id"] = [p[0] for p in all_pairs]
                    pair_features[feature_type]["merchant_id"] = [p[1] for p in all_pairs]
                except Exception as e:
                    print(f"âš ï¸ ç”¨æˆ·-å•†æˆ·{feature_type}ç‰¹å¾è®¡ç®—å¤±è´¥: {e}")

        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        if pair_features:
            # å…ˆæ„é€ æ‰€æœ‰æœ‰æ•ˆå¯¹çš„ DataFrame
            result_df = pd.DataFrame(all_pairs, columns=["user_id", "merchant_id"])
            # ä¾æ¬¡ merge æ¯ä¸ªç‰¹å¾ç±»å‹çš„ DataFrame
            for feature_type, feat_df in pair_features.items():
                result_df = result_df.merge(feat_df, on=["user_id", "merchant_id"], how="left")
            return result_df
        else:
            return pd.DataFrame({"user_id": [], "merchant_id": []})

    def get_feature_names(self):
        """è·å–æ‰€æœ‰ç‰¹å¾åç§°"""
        if not self.is_fitted:
            raise ValueError("Transformer has not been fitted yet.")

        feature_names = []

        if self.user_tfidf_features is not None:
            feature_names.extend([col for col in self.user_tfidf_features.columns if col != "user_id"])

        if self.merchant_tfidf_features is not None:
            feature_names.extend([col for col in self.merchant_tfidf_features.columns if col != "merchant_id"])

        if self.user_merchant_tfidf_features is not None:
            feature_names.extend(
                [col for col in self.user_merchant_tfidf_features.columns if col not in ["user_id", "merchant_id"]]
            )

        return feature_names


if __name__ == "__main__":
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ•°æ®é›†
    import numpy as np

    # æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•
    np.random.seed(42)
    n_samples = 1000

    test_data = {
        "user_id": np.random.randint(1, 100, n_samples),
        "merchant_id": np.random.randint(1, 50, n_samples),
        "activity_log": [
            f"item_{np.random.randint(1, 500)}:cat_{np.random.randint(1, 20)}:brand_{np.random.randint(1, 30)}:202401:1#"
            + f"item_{np.random.randint(1, 500)}:cat_{np.random.randint(1, 20)}:brand_{np.random.randint(1, 30)}:202402:2"
            for _ in range(n_samples)
        ],
    }

    df = pd.DataFrame(test_data)
    X = df
    y = np.random.randint(0, 2, n_samples)

    print("ğŸ§ª ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•...")
    print(f"æ¨¡æ‹Ÿæ•°æ®å½¢çŠ¶: {X.shape}")

    transformer = TfidfTransformer(top_n_features=50, min_df=1, max_df=0.95)
    transformer.fit(X, y)

    transformed_df = transformer.transform(X)
    print(f"è½¬æ¢åçš„æ•°æ®å½¢çŠ¶: {transformed_df.shape}")
    print(f"ç‰¹å¾åç§°å‰10ä¸ª: {transformer.get_feature_names()[:10]}")
    print(f"è½¬æ¢åçš„æ•°æ®é¢„è§ˆ:\n{transformed_df.head()}")
